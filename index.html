<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Body Tracking AR – Robust Version</title>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>

<style>
html, body {
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: black;
  overflow: hidden;
}

video, canvas {
  position: absolute;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
  pointer-events: none;
}

#start {
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
  background: black;
  color: white;
  font-size: 36px;
  z-index: 9999;
  cursor: pointer;
}

#debug {
  position: fixed;
  top: 10px;
  left: 10px;
  color: lime;
  font-size: 16px;
  z-index: 10;
}
</style>
</head>
<body>

<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<div id="debug">Initializing…</div>
<div id="start">TAP TO START</div>

<script>
const startBtn = document.getElementById("start");
const debug = document.getElementById("debug");
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

let pose = null;
let lastLandmarks = []; // store last frame for interpolation

startBtn.addEventListener("click", async () => {
  if (document.documentElement.requestFullscreen) {
    await document.documentElement.requestFullscreen();
  }
  startBtn.style.display = "none";
  await startBackCamera();
});

async function startBackCamera() {
  debug.textContent = "Looking for back camera…";

  const devices = await navigator.mediaDevices.enumerateDevices();
  const backCamera = devices.find(d => d.kind === "videoinput" && d.label.toLowerCase().includes("back"));

  if (!backCamera) {
    debug.textContent = "No back camera found!";
    return;
  }

  debug.textContent = `Back camera found: ${backCamera.label}`;

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { deviceId: { exact: backCamera.deviceId }, width: 1280, height: 720 },
    audio: false
  });

  video.srcObject = stream;

  pose = new Pose({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
  });

  pose.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    minDetectionConfidence: 0.5, // lower to detect partially visible people
    minTrackingConfidence: 0.5
  });

  pose.onResults(drawRobustLandmarks);

  async function loop() {
    if(video.readyState >= 2) {
      await pose.send({ image: video });
    }
    requestAnimationFrame(loop);
  }

  loop();
}

// --- Draw landmarks with robustness ---
function drawRobustLandmarks(results) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  if (!results.poseLandmarks) {
    debug.textContent = "No body detected";
    return;
  }

  debug.textContent = "Body detected";

  const landmarks = [];

  // interpolate missing landmarks using last frame
  results.poseLandmarks.forEach((lm, i) => {
    if (lm.visibility < 0.5 && lastLandmarks[i]) {
      // use last known position if current is unreliable
      landmarks[i] = lastLandmarks[i];
    } else {
      landmarks[i] = lm;
    }
  });

  lastLandmarks = landmarks;

  // draw landmarks
  landmarks.forEach(lm => {
    const x = lm.x * canvas.width;
    const y = lm.y * canvas.height;
    ctx.beginPath();
    ctx.arc(x, y, 6, 0, Math.PI * 2);
    ctx.fillStyle = "yellow";
    ctx.fill();
  });
}
</script>

</body>
</html>
