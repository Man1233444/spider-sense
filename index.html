<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>3D Predictive AR Throw</title>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

<style>
html, body {
  margin: 0;
  padding: 0;
  background: black;
  overflow: hidden;
  width: 100%;
  height: 100%;
}

#start {
  position: fixed;
  inset: 0;
  background: black;
  color: white;
  font-size: 32px;
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 10;
}

#debug {
  position: fixed;
  top: 10px;
  left: 10px;
  color: lime;
  font-size: 16px;
  z-index: 20;
}

video, canvas {
  position: absolute;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
}
</style>
</head>
<body>

<div id="start">TAP TO START</div>
<div id="debug">Initializing…</div>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
const start = document.getElementById("start");
const debug = document.getElementById("debug");
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

let prevTip = null;
let prevWrist = null;

start.addEventListener("click", async () => {
  if (document.documentElement.requestFullscreen) {
    await document.documentElement.requestFullscreen();
  }
  start.style.display = "none";
  await startBackCamera();
});

// === Back Camera ===
async function startBackCamera() {
  debug.textContent = "Looking for back camera…";

  const devices = await navigator.mediaDevices.enumerateDevices();
  const backCamera = devices.find(d => d.kind === "videoinput" && d.label.toLowerCase().includes("back"));

  if (!backCamera) {
    debug.textContent = "No back camera found!";
    return;
  }

  debug.textContent = `Back camera found: ${backCamera.label}`;

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { deviceId: { exact: backCamera.deviceId }, width: 1280, height: 720 },
    audio: false
  });

  video.srcObject = stream;

  const hands = new Hands({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
  });

  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
  });

  hands.onResults(onResults);

  async function loop() {
    await hands.send({ image: video });
    requestAnimationFrame(loop);
  }

  loop();
}

// === Predictive trajectory for index finger (landmark 8) ===
function onResults(results) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  if (!results.multiHandLandmarks || results.multiHandLandmarks.length === 0) {
    debug.textContent = "Back camera active – NO HAND";
    prevTip = null;
    prevWrist = null;
    return;
  }

  debug.textContent = "Back camera active – HAND DETECTED";

  const landmarks = results.multiHandLandmarks[0];

  // Smooth all landmarks
  for (let i = 0; i < landmarks.length; i++) {
    if (!landmarks[i].prev) landmarks[i].prev = { x: landmarks[i].x, y: landmarks[i].y, z: landmarks[i].z };
    landmarks[i].x = 0.5 * landmarks[i].x + 0.5 * landmarks[i].prev.x;
    landmarks[i].y = 0.5 * landmarks[i].y + 0.5 * landmarks[i].prev.y;
    landmarks[i].z = 0.5 * landmarks[i].z + 0.5 * landmarks[i].prev.z;
    landmarks[i].prev.x = landmarks[i].x;
    landmarks[i].prev.y = landmarks[i].y;
    landmarks[i].prev.z = landmarks[i].z;
  }

  drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: "cyan", lineWidth: 3 });
  drawLandmarks(ctx, landmarks, { color: "yellow", radius: 4 });

  const wrist = landmarks[0];
  const base = landmarks[5]; // index base
  const tip = landmarks[8];  // index tip

  const startX = base.x * canvas.width;
  const startY = base.y * canvas.height;

  // Hand velocity (speed)
  let speed = 0.1;
  if(prevTip) {
    const dx = (tip.x - prevTip.x) * canvas.width;
    const dy = (tip.y - prevTip.y) * canvas.height;
    speed = Math.sqrt(dx*dx + dy*dy);
  }
  prevTip = { x: tip.x, y: tip.y };

  // 3D direction vector
  const dxNorm = tip.x - base.x;
  const dyNorm = tip.y - base.y;
  const dzNorm = tip.z - base.z;

  const vecLength = Math.sqrt(dxNorm*dxNorm + dyNorm*dyNorm + dzNorm*dzNorm);
  if(vecLength === 0) return;

  const nx = dxNorm / vecLength;
  const ny = dyNorm / vecLength;
  const nz = dzNorm / vecLength;

  // Scale by hand speed
  const lineScale = Math.min(Math.max(speed * 20, 100), 600);

  // --- Predict trajectory ---
  let x = startX;
  let y = startY;
  let vx = nx * lineScale;
  let vy = ny * lineScale;

  ctx.beginPath();
  ctx.moveTo(x, y);

  for (let i = 0; i < 100; i++) { // longer prediction
    vy += 28; // gravity
    x += vx * 0.02;
    y += vy * 0.02;

    // bounce off bottom
    if(y > canvas.height * 0.9) {
      vy *= -0.6;
      vx *= 0.9; // dampen horizontal after bounce
    }

    ctx.lineTo(x, y);

    // Stop prediction if off-screen
    if(x < 0 || x > canvas.width || y > canvas.height) break;
  }

  ctx.strokeStyle = "lime";
  ctx.lineWidth = 4;
  ctx.stroke();
}
</script>

</body>
</html>
