<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Body Tracking AR – Fullscreen Start</title>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>

<style>
html, body {
  margin: 0;
  padding: 0;
  background: black;
  overflow: hidden;
  width: 100%;
  height: 100%;
}

#start {
  position: fixed;
  inset: 0;
  background: black;
  color: white;
  font-size: 36px;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 30;
  cursor: pointer;
}

#loading {
  position: fixed;
  inset: 0;
  background: black;
  color: white;
  font-size: 36px;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 20;
  display: none;
}

video, canvas {
  position: absolute;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
}

#debug {
  position: fixed;
  top: 10px;
  left: 10px;
  color: lime;
  font-size: 16px;
  z-index: 10;
}
</style>
</head>
<body>

<div id="start">TAP TO START</div>
<div id="loading">Loading camera…</div>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<div id="debug">Initializing…</div>

<script>
const startBtn = document.getElementById("start");
const loading = document.getElementById("loading");
const debug = document.getElementById("debug");
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

let pose = null;

startBtn.addEventListener("click", async () => {
  // Enter fullscreen
  if (document.documentElement.requestFullscreen) {
    await document.documentElement.requestFullscreen();
  }
  startBtn.style.display = "none"; // hide start button
  loading.style.display = "flex";  // show loading screen
  await startBackCamera();
});

// --- Start back camera ---
async function startBackCamera() {
  debug.textContent = "Looking for back camera…";

  const devices = await navigator.mediaDevices.enumerateDevices();
  const backCamera = devices.find(d => d.kind === "videoinput" && d.label.toLowerCase().includes("back"));

  if (!backCamera) {
    debug.textContent = "No back camera found!";
    loading.textContent = "No back camera found!";
    return;
  }

  debug.textContent = `Back camera found: ${backCamera.label}`;

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { deviceId: { exact: backCamera.deviceId }, width: 1280, height: 720 },
    audio: false
  });

  video.srcObject = stream;

  video.onloadedmetadata = () => {
    loading.style.display = "none"; // hide loading screen when video is ready
  };

  // --- MediaPipe Pose ---
  pose = new Pose({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
  });

  pose.setOptions({
    modelComplexity: 1,
    smoothLandmarks: true,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
  });

  pose.onResults(drawLandmarksOnly);

  async function loop() {
    if(video.readyState >= 2) {
      await pose.send({ image: video });
    }
    requestAnimationFrame(loop);
  }

  loop();
}

// --- Draw only landmarks manually ---
function drawLandmarksOnly(results) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  if (!results.poseLandmarks) {
    debug.textContent = "No body detected";
    return;
  }

  debug.textContent = "Body detected";

  // Draw only points/joints (yellow circles)
  results.poseLandmarks.forEach(lm => {
    const x = lm.x * canvas.width;
    const y = lm.y * canvas.height;
    ctx.beginPath();
    ctx.arc(x, y, 6, 0, Math.PI * 2);
    ctx.fillStyle = "yellow";
    ctx.fill();
  });
}
</script>

</body>
</html>
