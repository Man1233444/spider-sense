<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Hand Aim – Back Camera</title>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

<style>
html, body {
  margin: 0;
  padding: 0;
  background: black;
  overflow: hidden;
  width: 100%;
  height: 100%;
}

#start {
  position: fixed;
  inset: 0;
  background: black;
  color: white;
  font-size: 32px;
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 10;
}

#debug {
  position: fixed;
  top: 10px;
  left: 10px;
  color: lime;
  font-size: 16px;
  z-index: 20;
}

video, canvas {
  position: absolute;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
}
</style>
</head>
<body>

<div id="start">TAP TO START</div>
<div id="debug">Initializing…</div>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
const start = document.getElementById("start");
const debug = document.getElementById("debug");
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

start.addEventListener("click", async () => {
  if (document.documentElement.requestFullscreen) {
    await document.documentElement.requestFullscreen();
  }
  start.style.display = "none";
  await startBackCamera();
});

async function startBackCamera() {
  debug.textContent = "Looking for back camera…";

  const devices = await navigator.mediaDevices.enumerateDevices();
  const backCamera = devices.find(d => d.kind === "videoinput" && d.label.toLowerCase().includes("back"));

  if (!backCamera) {
    debug.textContent = "No back camera found!";
    return;
  }

  debug.textContent = `Back camera found: ${backCamera.label}`;

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { deviceId: { exact: backCamera.deviceId }, width: 1280, height: 720 },
    audio: false
  });

  video.srcObject = stream;

  const hands = new Hands({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
  });

  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
  });

  hands.onResults(onResults);

  async function loop() {
    await hands.send({ image: video });
    requestAnimationFrame(loop);
  }

  loop();
}

// === Hand drawing + aim line ===
function onResults(results) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  if (!results.multiHandLandmarks || results.multiHandLandmarks.length === 0) {
    debug.textContent = "Back camera active – NO HAND";
    return;
  }

  debug.textContent = "Back camera active – HAND DETECTED";

  const landmarks = results.multiHandLandmarks[0];

  drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: "cyan", lineWidth: 3 });
  drawLandmarks(ctx, landmarks, { color: "yellow", radius: 4 });

  const base = landmarks[5]; // index finger base
  const tip = landmarks[8];  // index finger tip

  const startX = base.x * canvas.width;
  const startY = base.y * canvas.height;

  const dx = tip.x - base.x;
  const dy = tip.y - base.y;

 // Calculate normalized direction for index finger
const dxNorm = (tip.x - base.x) * canvas.width;
const dyNorm = (tip.y - base.y) * canvas.height;
const length = Math.sqrt(dxNorm*dxNorm + dyNorm*dyNorm);
if(length === 0) return;

const nx = dxNorm / length;
const ny = dyNorm / length;

// Aim line physics
let x = startX;
let y = startY;
let vx = nx * 300; // initial velocity scaled
let vy = ny * 300;

ctx.beginPath();
ctx.moveTo(x, y);

for (let i = 0; i < 50; i++) {
  vy += 28; // gravity
  x += vx * 0.02;
  y += vy * 0.02;

  // bounce off bottom
  if(y > canvas.height * 0.9) {
    vy *= -0.6;
  }

  ctx.lineTo(x, y);
}
ctx.strokeStyle = "lime";
ctx.lineWidth = 4;
ctx.stroke();

  ctx.strokeStyle = "lime";
  ctx.lineWidth = 4;
  ctx.stroke();
}
</script>

</body>
</html>
