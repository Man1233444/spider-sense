<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Back-Camera Hand Aim</title>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

<style>
html, body {
  margin: 0;
  padding: 0;
  background: black;
  overflow: hidden;
  width: 100%;
  height: 100%;
}

#start {
  position: fixed;
  inset: 0;
  background: black;
  color: white;
  font-size: 32px;
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 10;
}

video, canvas {
  position: absolute;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
}

#debug {
  position: fixed;
  top: 10px;
  left: 10px;
  color: lime;
  font-size: 16px;
  z-index: 20;
}
</style>
</head>
<body>

<div id="start">TAP TO START</div>
<div id="debug">Initializing…</div>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script>
const start = document.getElementById("start");
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const debug = document.getElementById("debug");

canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

start.addEventListener("click", async () => {
  if (document.documentElement.requestFullscreen) {
    await document.documentElement.requestFullscreen();
  }
  start.style.display = "none";
  startBackCamera();
});

// === BACK CAMERA SETUP (from old Spider Sense code) ===
async function startBackCamera() {
  debug.textContent = "Requesting back camera…";

  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      facingMode: { exact: "environment" },
      width: { ideal: 1280 },
      height: { ideal: 720 }
    },
    audio: false
  });

  video.srcObject = stream;
  debug.textContent = "Back camera active";

  // === Hand tracking setup ===
  const hands = new Hands({
    locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
  });

  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
  });

  hands.onResults(onResults);

  async function loop() {
    await hands.send({ image: video });
    requestAnimationFrame(loop);
  }

  loop();
}

// === Draw hand + aiming line ===
function onResults(results) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  if (!results.multiHandLandmarks || results.multiHandLandmarks.length === 0) {
    debug.textContent = "Back camera active – NO HAND";
    return;
  }

  debug.textContent = "Back camera active – HAND DETECTED";

  const landmarks = results.multiHandLandmarks[0];

  // Draw hand for debug
  drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
    color: "cyan",
    lineWidth: 3
  });
  drawLandmarks(ctx, landmarks, {
    color: "yellow",
    radius: 4
  });

  // Aim line from index finger
  const base = landmarks[5]; // index finger base
  const tip = landmarks[8];  // index finger tip

  const startX = base.x * canvas.width;
  const startY = base.y * canvas.height;

  const dx = tip.x - base.x;
  const dy = tip.y - base.y;

  let x = startX;
  let y = startY;

  let vx = dx * 1400;
  let vy = dy * 1400;

  ctx.beginPath();
  ctx.moveTo(x, y);

  for (let i = 0; i < 50; i++) {
    vy += 28; // gravity
    x += vx * 0.02;
    y += vy * 0.02;
    ctx.lineTo(x, y);
  }

  ctx.strokeStyle = "lime";
  ctx.lineWidth = 4;
  ctx.stroke();
}
</script>

</body>
</html>
